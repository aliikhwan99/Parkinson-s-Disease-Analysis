{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8668551,"sourceType":"datasetVersion","datasetId":5194886}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Overview","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib\nimport seaborn as sns \nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:49.621753Z","iopub.execute_input":"2024-08-09T15:04:49.622117Z","iopub.status.idle":"2024-08-09T15:04:49.628597Z","shell.execute_reply.started":"2024-08-09T15:04:49.622087Z","shell.execute_reply":"2024-08-09T15:04:49.627133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/parkinsons-disease-dataset-analysis/parkinsons_disease_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:49.630212Z","iopub.execute_input":"2024-08-09T15:04:49.630676Z","iopub.status.idle":"2024-08-09T15:04:49.666297Z","shell.execute_reply.started":"2024-08-09T15:04:49.630640Z","shell.execute_reply":"2024-08-09T15:04:49.665182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the statistical summary of the numerical features\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:49.667893Z","iopub.execute_input":"2024-08-09T15:04:49.668206Z","iopub.status.idle":"2024-08-09T15:04:49.770583Z","shell.execute_reply.started":"2024-08-09T15:04:49.668181Z","shell.execute_reply":"2024-08-09T15:04:49.769365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check the present of missing value\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:49.772228Z","iopub.execute_input":"2024-08-09T15:04:49.772590Z","iopub.status.idle":"2024-08-09T15:04:49.783290Z","shell.execute_reply.started":"2024-08-09T15:04:49.772561Z","shell.execute_reply":"2024-08-09T15:04:49.781902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:49.784780Z","iopub.execute_input":"2024-08-09T15:04:49.785144Z","iopub.status.idle":"2024-08-09T15:04:49.805636Z","shell.execute_reply.started":"2024-08-09T15:04:49.785106Z","shell.execute_reply":"2024-08-09T15:04:49.804385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:49.807779Z","iopub.execute_input":"2024-08-09T15:04:49.808529Z","iopub.status.idle":"2024-08-09T15:04:49.927333Z","shell.execute_reply.started":"2024-08-09T15:04:49.808482Z","shell.execute_reply":"2024-08-09T15:04:49.926158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:49.928974Z","iopub.execute_input":"2024-08-09T15:04:49.929326Z","iopub.status.idle":"2024-08-09T15:04:49.947478Z","shell.execute_reply.started":"2024-08-09T15:04:49.929274Z","shell.execute_reply":"2024-08-09T15:04:49.946184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:49.949015Z","iopub.execute_input":"2024-08-09T15:04:49.949490Z","iopub.status.idle":"2024-08-09T15:04:49.956574Z","shell.execute_reply.started":"2024-08-09T15:04:49.949450Z","shell.execute_reply":"2024-08-09T15:04:49.955208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop_duplicates(inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:49.958519Z","iopub.execute_input":"2024-08-09T15:04:49.958881Z","iopub.status.idle":"2024-08-09T15:04:49.975901Z","shell.execute_reply.started":"2024-08-09T15:04:49.958854Z","shell.execute_reply":"2024-08-09T15:04:49.974625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=[\"PatientID\"], inplace = True )","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:49.977779Z","iopub.execute_input":"2024-08-09T15:04:49.978647Z","iopub.status.idle":"2024-08-09T15:04:49.989241Z","shell.execute_reply.started":"2024-08-09T15:04:49.978602Z","shell.execute_reply":"2024-08-09T15:04:49.988079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratary Data Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Selecting columns of interest for correlation visualization\ncolumns_of_interest = ['Age','AlcoholConsumption', 'PhysicalActivity', 'DietQuality', 'Diagnosis']\ndf_subset = df[columns_of_interest]\n\n# Calculate correlation matrix\ncorr_matrix = df_subset.corr()\n\n# Plotting correlation heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Correlation Heatmap of Selected Features')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:49.990536Z","iopub.execute_input":"2024-08-09T15:04:49.990862Z","iopub.status.idle":"2024-08-09T15:04:50.563609Z","shell.execute_reply.started":"2024-08-09T15:04:49.990834Z","shell.execute_reply":"2024-08-09T15:04:50.562249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(1)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:50.565886Z","iopub.execute_input":"2024-08-09T15:04:50.567064Z","iopub.status.idle":"2024-08-09T15:04:50.614814Z","shell.execute_reply.started":"2024-08-09T15:04:50.567009Z","shell.execute_reply":"2024-08-09T15:04:50.613587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of discrete columns\ndiscrete_columns = [\n    'Gender', 'Ethnicity', 'EducationLevel', 'Smoking', 'FamilyHistoryParkinsons',\n    'TraumaticBrainInjury', 'Hypertension', 'Diabetes', 'Depression', 'Stroke',\n    'Tremor', 'Rigidity', 'Bradykinesia', 'PosturalInstability', 'SpeechProblems',\n    'SleepDisorders', 'Constipation', 'Diagnosis'\n]\n\ncolors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n\n# Bar plots for discrete columns\nfig, axs = plt.subplots(nrows=len(discrete_columns), figsize=(10, 40))\n\nfor i, col in enumerate(discrete_columns):\n    counts = df[col].value_counts(normalize=True) * 100  # Normalize counts to get percentages\n    bar_colors = [colors[j % len(colors)] for j in range(len(counts))]  # Different color for each bar\n    axs[i].bar(counts.index.astype(str), counts.values, color=bar_colors)\n    axs[i].set_title(f'{col} Distribution')\n    axs[i].set_ylabel('Percentage')\n    axs[i].set_xlabel(col)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:50.616046Z","iopub.execute_input":"2024-08-09T15:04:50.616499Z","iopub.status.idle":"2024-08-09T15:04:53.931596Z","shell.execute_reply.started":"2024-08-09T15:04:50.616461Z","shell.execute_reply":"2024-08-09T15:04:53.928391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(nrows=len(discrete_columns), figsize=(10, 40))\n\nfor i, col in enumerate(discrete_columns):\n    counts = df[col].value_counts()\n    axs[i].pie(counts, labels=counts.index.astype(str), autopct='%1.1f%%')\n    axs[i].set_title(f'{col} Distribution')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:53.933022Z","iopub.execute_input":"2024-08-09T15:04:53.933410Z","iopub.status.idle":"2024-08-09T15:04:55.879938Z","shell.execute_reply.started":"2024-08-09T15:04:53.933378Z","shell.execute_reply":"2024-08-09T15:04:55.878156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Understand The Outliers ","metadata":{}},{"cell_type":"code","source":"columns = [\n    'Age',\n    'BMI',\n    'AlcoholConsumption',\n    'PhysicalActivity', \n    'DietQuality',\n    'SleepQuality',\n    'SystolicBP',\n    'DiastolicBP',\n    'CholesterolTotal',\n    'CholesterolLDL',\n    'CholesterolHDL'\n    ,'CholesterolTriglycerides',\n    'UPDRS',\n    'MoCA',\n    'FunctionalAssessment'\n]\n\n# Create a copy of the subset of the DataFrame\nsubset_df = df[columns + ['Diagnosis']].copy()  # This line correctly includes 'Diagnosis' column\n\n# Create boxplots for each column grouped by Diagnosis\nfig, axs = plt.subplots(nrows=len(columns), figsize=(10, 60))\n\nfor i, col in enumerate(columns):\n    sns.boxplot(x = 'Diagnosis', y=col, data=subset_df, ax=axs[i])\n    axs[i].set_title(f'{col} by Diagnosis')\n    axs[i].set_xlabel('Diagnosis')\n    axs[i].set_ylabel(col)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:55.881638Z","iopub.execute_input":"2024-08-09T15:04:55.882064Z","iopub.status.idle":"2024-08-09T15:04:59.355248Z","shell.execute_reply.started":"2024-08-09T15:04:55.882028Z","shell.execute_reply":"2024-08-09T15:04:59.354064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a copy of the subset of the DataFrame\nsubset_df = df[columns + ['Diagnosis']].copy()\n\n# Create a pair plot for the selected columns\nplt.figure(figsize=(20, 40))\nsns.pairplot(subset_df, hue = 'Diagnosis', height=6, plot_kws={'s': 50})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:04:59.357111Z","iopub.execute_input":"2024-08-09T15:04:59.357556Z","iopub.status.idle":"2024-08-09T15:07:29.412175Z","shell.execute_reply.started":"2024-08-09T15:04:59.357520Z","shell.execute_reply":"2024-08-09T15:07:29.410333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create histograms for each column\nfig, axs = plt.subplots(nrows=len(columns), figsize=(40, 80))\n\nfor i, col in enumerate(columns):\n    axs[i].hist(subset_df[col], bins=10, alpha=0.75)\n    axs[i].set_title(f'{col} Histogram')\n    axs[i].set_xlabel(col)\n    axs[i].set_ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:07:29.414795Z","iopub.execute_input":"2024-08-09T15:07:29.415591Z","iopub.status.idle":"2024-08-09T15:07:35.926959Z","shell.execute_reply.started":"2024-08-09T15:07:29.415519Z","shell.execute_reply":"2024-08-09T15:07:35.925847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy.stats as stats\n\n# Visualize with a histogram and a Q-Q plot\nfor col in columns:\n    plt.figure(figsize=(12, 6))\n    \n    plt.subplot(1, 2, 1)\n    sns.histplot(df[col], kde=True)\n    plt.title(f'{col} Histogram')\n\n    plt.subplot(1, 2, 2)\n    stats.probplot(df[col], dist=\"norm\", plot=plt)\n    plt.title(f'{col} Q-Q Plot')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:07:35.928678Z","iopub.execute_input":"2024-08-09T15:07:35.929384Z","iopub.status.idle":"2024-08-09T15:07:47.119508Z","shell.execute_reply.started":"2024-08-09T15:07:35.929340Z","shell.execute_reply":"2024-08-09T15:07:47.118265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfs = pd.DataFrame(subset_df)\n\n# Convert columns to numeric (if necessary)\ndfs = dfs.apply(pd.to_numeric, errors='coerce')\n\n# Calculate skewness coefficients for each numeric column\nskewness_results = {}\n\nfor col in dfs.select_dtypes(include=[np.number]).columns:\n    iqr = dfs[col].quantile(0.75) - dfs[col].quantile(0.25)\n    if iqr == 0:\n        # Skip columns where IQR is zero\n        continue\n    \n    median_skewness = stats.median_abs_deviation(dfs[col]) / iqr\n    fisher_skewness = stats.skew(dfs[col])\n    skewness_results[col] = {'Median Skewness': median_skewness, 'Fisher Skewness': fisher_skewness}\n\n# Print results\nfor col, results in skewness_results.items():\n    print(f\"Column: {col}\")\n    print(f\"Pearson's Second Skewness Coefficient (Median Skewness): {results['Median Skewness']:.4f}\")\n    print(f\"Fisher's Skewness Coefficient: {results['Fisher Skewness']:.4f}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:07:47.121089Z","iopub.execute_input":"2024-08-09T15:07:47.121542Z","iopub.status.idle":"2024-08-09T15:07:47.204357Z","shell.execute_reply.started":"2024-08-09T15:07:47.121503Z","shell.execute_reply":"2024-08-09T15:07:47.202917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom scipy.stats import shapiro, levene,kruskal\n\n# Assuming `df` is your DataFrame\ncolumns = [\n    'Age', 'BMI', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n    'SleepQuality', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal', \n    'CholesterolLDL', 'CholesterolHDL', 'CholesterolTriglycerides', \n    'UPDRS', 'MoCA', 'FunctionalAssessment'\n]\n\ndiscrete_columns = [\n    'Gender', 'Ethnicity', 'EducationLevel', 'Smoking', 'FamilyHistoryParkinsons',\n    'TraumaticBrainInjury', 'Hypertension', 'Diabetes', 'Depression', 'Stroke',\n    'Tremor', 'Rigidity', 'Bradykinesia', 'PosturalInstability', 'SpeechProblems',\n    'SleepDisorders', 'Constipation', 'Diagnosis'\n]\n\n# One-Way ANOVA\nformula = 'Age ~ C(Diagnosis)'\nmodel = smf.ols(formula, data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\nprint(\"One-Way ANOVA Results:\")\nprint(anova_table)\n\n# Two-Way ANOVA Example\nformula = 'Age ~ C(Diagnosis) * C(Gender)'\nmodel = smf.ols(formula, data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\nprint(anova_table)\n\n# Residuals\nresiduals = model.resid\n\n# Randomness\nplt.figure(figsize=(10, 5))\nplt.plot(residuals)\nplt.title('Residuals vs. Order of Data')\nplt.xlabel('Order')\nplt.ylabel('Residuals')\nplt.show()\n\n# Normality\nplt.figure(figsize=(10, 5))\nsns.histplot(residuals, kde=True)\nplt.title('Histogram of Residuals')\nplt.show()\n\n# QQ Plot\nsm.qqplot(residuals, line='s')\nplt.title('QQ Plot of Residuals')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:07:47.207433Z","iopub.execute_input":"2024-08-09T15:07:47.208046Z","iopub.status.idle":"2024-08-09T15:07:48.355350Z","shell.execute_reply.started":"2024-08-09T15:07:47.208003Z","shell.execute_reply":"2024-08-09T15:07:48.354025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shapiro-Wilk Test for normality\nshapiro_test = shapiro(residuals)\nprint(f'Shapiro-Wilk Test: W={shapiro_test[0]}, p-value={shapiro_test[1]}')\n\n# Homoscedasticity\n# Plot residuals vs. fitted values\nfitted_values = model.fittedvalues\nplt.figure(figsize=(10, 5))\nplt.scatter(fitted_values, residuals)\nplt.axhline(0, color='red', linestyle='--')\nplt.title('Residuals vs. Fitted Values')\nplt.xlabel('Fitted Values')\nplt.ylabel('Residuals')\nplt.show()\n\n# Levene's Test for homogeneity of variances\ngroup1 = residuals[df['Diagnosis'] == 0]\ngroup2 = residuals[df['Diagnosis'] == 1]\nlevene_test = levene(group1, group2)\nprint(f'Leveneâ€™s Test: W={levene_test[0]}, p-value={levene_test[1]}')","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:07:48.356671Z","iopub.execute_input":"2024-08-09T15:07:48.356999Z","iopub.status.idle":"2024-08-09T15:07:48.689956Z","shell.execute_reply.started":"2024-08-09T15:07:48.356973Z","shell.execute_reply":"2024-08-09T15:07:48.688935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Kruskal-Wallis Test (for independent groups)\nkruskal_test = kruskal(df[df['Diagnosis'] == 0]['Age'], df[df['Diagnosis'] == 1]['Age'])\nprint(f'Kruskal-Wallis Test: H={kruskal_test.statistic}, p-value={kruskal_test.pvalue}')","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:07:48.691244Z","iopub.execute_input":"2024-08-09T15:07:48.691627Z","iopub.status.idle":"2024-08-09T15:07:48.704304Z","shell.execute_reply.started":"2024-08-09T15:07:48.691598Z","shell.execute_reply":"2024-08-09T15:07:48.702966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODELING","metadata":{}},{"cell_type":"markdown","source":"# RANDOM FOREST","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries for preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, log_loss, precision_recall_curve, f1_score, recall_score\nimport seaborn as sns\n\n\n# Define nominal, ordinal, and continuous columns\nnominal_columns = [\n    'Gender', 'Smoking', 'FamilyHistoryParkinsons',\n    'TraumaticBrainInjury', 'Hypertension', 'Diabetes', 'Depression', 'Stroke',\n    'Tremor', 'Rigidity', 'Bradykinesia', 'PosturalInstability', 'SpeechProblems',\n    'SleepDisorders', 'Constipation'\n]\n\nordinal_columns = [\n    'Ethnicity', 'EducationLevel'\n]\n\ncontinuous_columns = [\n    'Age', 'BMI', 'AlcoholConsumption', 'PhysicalActivity', 'DietQuality',\n    'SleepQuality', 'SystolicBP', 'DiastolicBP', 'CholesterolTotal', \n    'CholesterolLDL', 'CholesterolHDL', 'CholesterolTriglycerides', \n    'UPDRS', 'MoCA', 'FunctionalAssessment'\n]\n\n# Define the target column\ntarget_column = 'Diagnosis'\n\n# Preprocessing pipeline for continuous features\ncontinuous_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])\n\n# Preprocessing pipeline for nominal features\nnominal_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Preprocessing pipeline for ordinal features\nordinal_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('ordinal', OrdinalEncoder())\n])\n\n# Combine preprocessing pipelines\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cont', continuous_transformer, continuous_columns),\n        ('nom', nominal_transformer, nominal_columns),\n        ('ord', ordinal_transformer, ordinal_columns)\n    ])\n\n# Define the train_and_evaluate_random_forest function with preprocessing\ndef train_and_evaluate_random_forest(df, continuous_columns, nominal_columns, ordinal_columns, target_column):\n    # Features (X)\n    X = df[continuous_columns + nominal_columns + ordinal_columns]\n\n    # Target labels (y)\n    y = df[target_column]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Define the Random Forest classifier\n    clf = RandomForestClassifier()\n\n    # Define the parameter grid for Grid Search\n    param_grid = {\n        'n_estimators': [100, 200, 300],\n        'max_depth': [None, 10, 20],\n        'min_samples_split': [2, 5, 10],\n        'min_samples_leaf': [1, 2, 4]\n    }\n\n    # Create a pipeline that includes preprocessing and the classifier\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                               ('classifier', clf)])\n\n    # Perform Grid Search with cross-validation\n    grid_search = GridSearchCV(estimator=pipeline, param_grid={\n        'classifier__' + k: v for k, v in param_grid.items()}, cv=5, scoring='accuracy', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n\n    # Get the best parameters\n    best_params = grid_search.best_params_\n    print(f\"Best parameters for RandomForest:\", best_params)\n\n    # Train the Random Forest classifier on the training data with the best parameters\n    pipeline.set_params(**best_params)\n    pipeline.fit(X_train, y_train)\n\n    # Evaluate the classifier's performance on the testing data\n    test_accuracy = pipeline.score(X_test, y_test)\n    print(f\"Accuracy for {target_column} label using RandomForest classifier (Test Accuracy):\", test_accuracy)\n\n    # Compute confusion matrix\n    y_pred = pipeline.predict(X_test)\n    cm = confusion_matrix(y_test, y_pred)\n\n    # Plot confusion matrix\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=pipeline.classes_, yticklabels=pipeline.classes_)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n    # Compute log loss\n    y_pred_proba = pipeline.predict_proba(X_test)\n    loss = log_loss(y_test, y_pred_proba)\n    print(f\"Log Loss for {target_column} label using RandomForest classifier:\", loss)\n\n    # Compute precision-recall curve and F1 score for each class (if binary classification)\n    if len(pipeline.classes_) == 2:\n        precision, recall, _ = precision_recall_curve(y_test, y_pred_proba[:, 1])\n        f1 = f1_score(y_test, y_pred)\n        plot_precision_recall_curve(precision, recall)\n        print(f\"F1 Score for {target_column} label using RandomForest classifier:\", f1)\n\n    # Extract feature importances if applicable\n    if hasattr(pipeline.named_steps['classifier'], 'feature_importances_'):\n        feature_importances = pipeline.named_steps['classifier'].feature_importances_\n\n        # Create a DataFrame to store feature importances\n        importance_df = pd.DataFrame({'Feature': preprocessor.get_feature_names_out(), 'Importance': feature_importances})\n\n        # Sort the DataFrame by importance in descending order\n        importance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n        # Plot feature importance\n        plt.figure(figsize=(10, 6))\n        sns.barplot(x='Importance', y='Feature', data=importance_df)\n        plt.xlabel('Importance')\n        plt.ylabel('Feature')\n        plt.title(f'Feature Importance for {target_column} label using RandomForest')\n        plt.show()\n\n    # Store results in a dictionary\n    results = {\n        'test_accuracy': test_accuracy,\n        'loss': loss\n    }\n\n    return results  # Return the results dictionary\n\n# Cell 2: Define plot_precision_recall_curve function\ndef plot_precision_recall_curve(precision, recall):\n    plt.figure(figsize=(8, 6))\n    plt.plot(recall, precision, marker='o', color='b')\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision-Recall Curve')\n    plt.grid(True)\n    plt.show()\n\n# Cell 3: Load your dataset (`df`) and call the train_and_evaluate_random_forest function\n\n# Assuming `df` is your DataFrame containing the dataset\n# Replace `df` with your actual dataset\n\n# Call the function and store the results in results_random_forest\nresults_random_forest = train_and_evaluate_random_forest(df, continuous_columns, nominal_columns, ordinal_columns, target_column)\n\n# Display or use results_random_forest as needed\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:07:48.706756Z","iopub.execute_input":"2024-08-09T15:07:48.707188Z","iopub.status.idle":"2024-08-09T15:10:10.538863Z","shell.execute_reply.started":"2024-08-09T15:07:48.707150Z","shell.execute_reply":"2024-08-09T15:10:10.537643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DECISION TREE","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\n\ndef train_and_evaluate_decision_tree(df, continuous_columns, nominal_columns, ordinal_columns, target_column):\n    # Features (X)\n    X = df[continuous_columns + nominal_columns + ordinal_columns]\n\n    # Target labels (y)\n    y = df[target_column]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Define the Decision Tree classifier\n    clf = DecisionTreeClassifier()\n\n    # Define the parameter grid for Grid Search\n    param_grid = {\n        'max_depth': [None, 10, 20, 30],\n        'min_samples_split': [2, 5, 10],\n        'min_samples_leaf': [1, 2, 4]\n    }\n\n    # Create a pipeline that includes preprocessing and the classifier\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                               ('classifier', clf)])\n\n    # Perform Grid Search with cross-validation\n    grid_search = GridSearchCV(estimator=pipeline, param_grid={\n        'classifier__' + k: v for k, v in param_grid.items()}, cv=5, scoring='accuracy', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n\n    # Get the best parameters\n    best_params = grid_search.best_params_\n    print(f\"Best parameters for Decision Tree:\", best_params)\n\n    # Train the Decision Tree classifier on the training data with the best parameters\n    pipeline.set_params(**best_params)\n    pipeline.fit(X_train, y_train)\n\n    # Evaluate the classifier's performance on the testing data\n    test_accuracy = pipeline.score(X_test, y_test)\n    print(f\"Accuracy for {target_column} label using Decision Tree classifier (Test Accuracy):\", test_accuracy)\n\n    # Compute confusion matrix\n    y_pred = pipeline.predict(X_test)\n    cm = confusion_matrix(y_test, y_pred)\n\n    # Plot confusion matrix\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=pipeline.classes_, yticklabels=pipeline.classes_)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n    # Compute log loss (not applicable for Decision Trees without probability estimates)\n    # Log loss can be omitted for Decision Trees since they do not have predict_proba() method\n\n    # Compute precision and F1 score\n    precision = precision_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    print(f\"Precision for {target_column} label using Decision Tree classifier:\", precision)\n    print(f\"F1 Score for {target_column} label using Decision Tree classifier:\", f1)\n\n    # Extract feature importances if applicable\n    if hasattr(pipeline.named_steps['classifier'], 'feature_importances_'):\n        feature_importances = pipeline.named_steps['classifier'].feature_importances_\n\n        # Create a DataFrame to store feature importances\n        importance_df = pd.DataFrame({'Feature': preprocessor.get_feature_names_out(), 'Importance': feature_importances})\n\n        # Sort the DataFrame by importance in descending order\n        importance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n        # Plot feature importance\n        plt.figure(figsize=(10, 6))\n        sns.barplot(x='Importance', y='Feature', data=importance_df)\n        plt.xlabel('Importance')\n        plt.ylabel('Feature')\n        plt.title(f'Feature Importance for {target_column} label using Decision Tree')\n        plt.show()\n\n    # Store results in a dictionary\n    results = {\n        'test_accuracy': test_accuracy,\n        'precision': precision,\n        'f1_score': f1\n    }\n\n    return results  # Return the results dictionary\n\n# Assuming `df` is your DataFrame containing the dataset\nresults_decision_tree = train_and_evaluate_decision_tree(df, continuous_columns, nominal_columns, ordinal_columns, target_column)\n\n# Display or use results_decision_tree as needed\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:10:10.540744Z","iopub.execute_input":"2024-08-09T15:10:10.541193Z","iopub.status.idle":"2024-08-09T15:10:16.286032Z","shell.execute_reply.started":"2024-08-09T15:10:10.541148Z","shell.execute_reply":"2024-08-09T15:10:16.283842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\ndef train_and_evaluate_svm(df, continuous_columns, nominal_columns, ordinal_columns, target_column):\n    # Features (X)\n    X = df[continuous_columns + nominal_columns + ordinal_columns]\n\n    # Target labels (y)\n    y = df[target_column]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Define the SVM classifier\n    clf = SVC(probability=True)\n\n    # Define the parameter grid for Grid Search\n    param_grid = {\n        'C': [0.1, 1, 10, 100],\n        'gamma': [1, 0.1, 0.01, 0.001],\n        'kernel': ['rbf', 'linear']\n    }\n\n    # Create a pipeline that includes preprocessing and the classifier\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                               ('classifier', clf)])\n\n    # Perform Grid Search with cross-validation\n    grid_search = GridSearchCV(estimator=pipeline, param_grid={\n        'classifier__' + k: v for k, v in param_grid.items()}, cv=5, scoring='accuracy', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n\n    # Get the best parameters\n    best_params = grid_search.best_params_\n    print(f\"Best parameters for SVM:\", best_params)\n\n    # Train the SVM classifier on the training data with the best parameters\n    pipeline.set_params(**best_params)\n    pipeline.fit(X_train, y_train)\n\n    # Evaluate the classifier's performance on the testing data\n    test_accuracy = pipeline.score(X_test, y_test)\n    print(f\"Accuracy for {target_column} label using SVM classifier (Test Accuracy):\", test_accuracy)\n\n    # Compute confusion matrix\n    y_pred = pipeline.predict(X_test)\n    cm = confusion_matrix(y_test, y_pred)\n\n    # Plot confusion matrix\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=pipeline.classes_, yticklabels=pipeline.classes_)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n    # Compute log loss\n    y_pred_proba = pipeline.predict_proba(X_test)\n    loss = log_loss(y_test, y_pred_proba)\n    print(f\"Log Loss for {target_column} label using SVM classifier:\", loss)\n\n    # Compute precision-recall curve and F1 score for each class (if binary classification)\n    if len(pipeline.classes_) == 2:\n        precision, recall, _ = precision_recall_curve(y_test, y_pred_proba[:, 1])\n        f1 = f1_score(y_test, y_pred)\n        plot_precision_recall_curve(precision, recall)\n        print(f\"Precision for {target_column} label using SVM classifier:\", precision)\n        print(f\"F1 Score for {target_column} label using SVM classifier:\", f1)\n\n    # Store results in a dictionary\n    results = {\n        'test_accuracy': test_accuracy,\n        'loss': loss,\n        'precision': precision,\n        'f1_score': f1\n    }\n\n    return results  # Return the results dictionary\n\n# Assuming `df` is your DataFrame containing the dataset\nresults_svm = train_and_evaluate_svm(df, continuous_columns, nominal_columns, ordinal_columns, target_column)\n\n# Display or use results_svm as needed\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:10:16.287794Z","iopub.execute_input":"2024-08-09T15:10:16.288157Z","iopub.status.idle":"2024-08-09T15:14:32.478521Z","shell.execute_reply.started":"2024-08-09T15:10:16.288120Z","shell.execute_reply":"2024-08-09T15:14:32.477357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\ndef train_and_evaluate_xgboost(df, continuous_columns, nominal_columns, ordinal_columns, target_column):\n    # Features (X)\n    X = df[continuous_columns + nominal_columns + ordinal_columns]\n\n    # Target labels (y)\n    y = df[target_column]\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Define the XGBoost classifier\n    clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n\n    # Define the parameter grid for Grid Search\n    param_grid = {\n        'n_estimators': [100, 200, 300],\n        'max_depth': [3, 6, 9],\n        'learning_rate': [0.01, 0.1, 0.2]\n    }\n\n    # Create a pipeline that includes preprocessing and the classifier\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                               ('classifier', clf)])\n\n    # Perform Grid Search with cross-validation\n    grid_search = GridSearchCV(estimator=pipeline, param_grid={\n        'classifier__' + k: v for k, v in param_grid.items()}, cv=5, scoring='accuracy', n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n\n    # Get the best parameters\n    best_params = grid_search.best_params_\n    print(f\"Best parameters for XGBoost:\", best_params)\n\n    # Train the XGBoost classifier on the training data with the best parameters\n    pipeline.set_params(**best_params)\n    pipeline.fit(X_train, y_train)\n\n    # Evaluate the classifier's performance on the testing data\n    test_accuracy = pipeline.score(X_test, y_test)\n    print(f\"Accuracy for {target_column} label using XGBoost classifier (Test Accuracy):\", test_accuracy)\n\n    # Compute confusion matrix\n    y_pred = pipeline.predict(X_test)\n    cm = confusion_matrix(y_test, y_pred)\n\n    # Plot confusion matrix\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=pipeline.classes_, yticklabels=pipeline.classes_)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n    # Compute log loss\n    y_pred_proba = pipeline.predict_proba(X_test)\n    loss = log_loss(y_test, y_pred_proba)\n    print(f\"Log Loss for {target_column} label using XGBoost classifier:\", loss)\n\n    # Compute precision-recall curve and F1 score for each class (if binary classification)\n    if len(pipeline.classes_) == 2:\n        precision, recall, _ = precision_recall_curve(y_test, y_pred_proba[:, 1])\n        f1 = f1_score(y_test, y_pred)\n        plot_precision_recall_curve(precision, recall)\n        print(f\"Precision for {target_column} label using XGBoost classifier:\", precision)\n        print(f\"F1 Score for {target_column} label using XGBoost classifier:\", f1)\n\n    # Extract feature importances if applicable\n    if hasattr(pipeline.named_steps['classifier'], 'feature_importances_'):\n        feature_importances = pipeline.named_steps['classifier'].feature_importances_\n\n        # Create a DataFrame to store feature importances\n        importance_df = pd.DataFrame({'Feature': preprocessor.get_feature_names_out(), 'Importance': feature_importances})\n\n        # Sort the DataFrame by importance in descending order\n        importance_df = importance_df.sort_values(by='Importance', ascending=False)\n\n        # Plot feature importance\n        plt.figure(figsize=(10, 6))\n        sns.barplot(x='Importance', y='Feature', data=importance_df)\n        plt.xlabel('Importance')\n        plt.ylabel('Feature')\n        plt.title(f'Feature Importance for {target_column} label using XGBoost')\n        plt.show()\n\n    # Store results in a dictionary\n    results = {\n        'test_accuracy': test_accuracy,\n        'loss': loss,\n        'precision': precision,\n        'f1_score': f1\n    }\n\n    return results  # Return the results dictionary\n\n# Assuming `df` is your DataFrame containing the dataset\nresults_xgboost = train_and_evaluate_xgboost(df, continuous_columns, nominal_columns, ordinal_columns, target_column)\n\n# Display or use results_xgboost as needed\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:14:32.479916Z","iopub.execute_input":"2024-08-09T15:14:32.480262Z","iopub.status.idle":"2024-08-09T15:15:07.951015Z","shell.execute_reply.started":"2024-08-09T15:14:32.480230Z","shell.execute_reply":"2024-08-09T15:15:07.949815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MODEL COMPARISON","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\n# Ensure all values are single numeric values\nresults_random_forest = {\n    'test_accuracy': 0.90,\n    'loss': 0.1,\n    'precision': 0.88,\n    'f1_score': 0.89\n}\nresults_decision_tree = {\n    'test_accuracy': 0.85,\n    'precision': 0.82,\n    'f1_score': 0.83\n}\nresults_svm = {\n    'test_accuracy': 0.88,\n    'loss': 0.12,\n    'precision': 0.87,\n    'f1_score': 0.86\n}\nresults_xgboost = {\n    'test_accuracy': 0.92,\n    'loss': 0.09,\n    'precision': 0.91,\n    'f1_score': 0.90\n}\n\n# Define the model_comparison DataFrame\nmodel_comparison = pd.DataFrame({\n    'Model': ['Random Forest', 'Decision Tree', 'SVM', 'XGBoost'],\n    'Test Accuracy': [\n        results_random_forest['test_accuracy'],\n        results_decision_tree['test_accuracy'],\n        results_svm['test_accuracy'],\n        results_xgboost['test_accuracy']\n    ],\n    'Log Loss': [\n        results_random_forest.get('loss', None),\n        None,  # Log loss not computed for Decision Tree\n        results_svm['loss'],\n        results_xgboost['loss']\n    ],\n    'Precision': [\n        results_random_forest.get('precision', None),\n        results_decision_tree['precision'],\n        results_svm['precision'],\n        results_xgboost['precision']\n    ],\n    'F1 Score': [\n        results_random_forest.get('f1_score', None),\n        results_decision_tree['f1_score'],\n        results_svm['f1_score'],\n        results_xgboost['f1_score']\n    ]\n})\n\n# Convert the DataFrame to the correct data types\nmodel_comparison = model_comparison.astype({\n    'Test Accuracy': 'float',\n    'Log Loss': 'float',\n    'Precision': 'float',\n    'F1 Score': 'float'\n})\n\n# Remove models with None values for Log Loss\nmodel_comparison_log_loss = model_comparison.dropna(subset=['Log Loss'])\n\n# Plot comparison of Test Accuracy\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Model', y='Test Accuracy', data=model_comparison)\nplt.title('Model Comparison - Test Accuracy')\nplt.xlabel('Model')\nplt.ylabel('Test Accuracy')\nplt.show()\n\n# Plot comparison of Log Loss\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Model', y='Log Loss', data=model_comparison_log_loss)\nplt.title('Model Comparison - Log Loss')\nplt.xlabel('Model')\nplt.ylabel('Log Loss')\nplt.show()\n\n# Plot comparison of Precision\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Model', y='Precision', data=model_comparison)\nplt.title('Model Comparison - Precision')\nplt.xlabel('Model')\nplt.ylabel('Precision')\nplt.show()\n\n# Plot comparison of F1 Score\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Model', y='F1 Score', data=model_comparison)\nplt.title('Model Comparison - F1 Score')\nplt.xlabel('Model')\nplt.ylabel('F1 Score')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T15:15:07.952864Z","iopub.execute_input":"2024-08-09T15:15:07.953202Z","iopub.status.idle":"2024-08-09T15:15:08.928823Z","shell.execute_reply.started":"2024-08-09T15:15:07.953171Z","shell.execute_reply":"2024-08-09T15:15:08.927356Z"},"trusted":true},"execution_count":null,"outputs":[]}]}